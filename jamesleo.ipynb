{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BazaarVoice Challange\n",
    "\n",
    "## Background\n",
    "Machine learning models are capable of generating sequences of text that seem authentic to humans. Naturally, that ability could be used to produce fake reviews, at massive scale, and cause problems for review systems.For our challenge, we’ll provide two datasets. One dataset of fake reviews, that have been produced by a model, and then a dataset of real reviews. Our task is to develop a model that can classify a review as fake or authentic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YT07E0_S7hUn"
   },
   "outputs": [],
   "source": [
    "from sklearn import *\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9998\n"
     ]
    }
   ],
   "source": [
    "fakes = open(\"fake_reviews.txt\").readlines()\n",
    "reals = open(\"real_reviews.txt\").readlines()\n",
    "\n",
    "\n",
    "fakes2 = []\n",
    "for rev in  fakes:\n",
    "    rev = rev.replace('\\n', '')\n",
    "    fakes2.append(rev)\n",
    "\n",
    "reals2 = []\n",
    "for tv in  reals:\n",
    "    tv= tv.replace('\\n', '')\n",
    "    reals2.append(tv)\n",
    "\n",
    "\n",
    "fakeD = {key: 0 for (key) in fakes2}\n",
    "realD = {key: 1 for (key) in reals2}\n",
    "\n",
    "aRevs = {**fakeD, **realD}\n",
    "print(len(aRevs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "daf = shuffle(pd.DataFrame(list(aRevs.items()), columns=[\"Review\", \"Class\"]), random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "daf.to_pickle(\"./opDF.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5669</th>\n",
       "      <td>Bought this a week ago and so far, very impres...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8798</th>\n",
       "      <td>I just got this today in the mail and it’s so ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3205</th>\n",
       "      <td>Bought these for my use as a Christmas present...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8729</th>\n",
       "      <td>absolutely love these headphones- sound qualit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6412</th>\n",
       "      <td>I have had my unit for twenty years now and it...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review  Class\n",
       "5669  Bought this a week ago and so far, very impres...      1\n",
       "8798  I just got this today in the mail and it’s so ...      1\n",
       "3205  Bought these for my use as a Christmas present...      0\n",
       "8729  absolutely love these headphones- sound qualit...      1\n",
       "6412  I have had my unit for twenty years now and it...      1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(daf.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = daf[\"Review\"], daf[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yfwV6jNEGpzt"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=12 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7998,)\n",
      "(2000,)\n",
      "(7998,)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "k42ltteeDiIJ",
    "outputId": "fb4b72b4-74f5-4a54-c394-712faa6c9ff3"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv = TfidfVectorizer()\n",
    "x_train = cv.fit_transform(x_train)\n",
    "x_test = cv.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7998, 9538)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building The Classifier\n",
    "After having tried and tested over 10 algorithms, we settled on basic Adaboosting, which was the best mix of accuracy, efficiency and speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "viZNmCgHESfi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=0.5, n_estimators=130, random_state=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=130, learning_rate=.5)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hMofUnjaLJ_V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "ypreds = clf.predict(x_test)\n",
    "print(ypreds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Accuracy Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gBWgJnWjmlQA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.87\n",
      "Sklearn recall: 0.87\n",
      "Precision: 0.90\n",
      "Skearn precision: 0.90\n",
      "Accuracy: 0.89\n",
      "Sklearn accuracy: 0.89\n",
      "Average score=88.74451358637052\n"
     ]
    }
   ],
   "source": [
    "tpos, tneg, fpos, fneg = 0, 0, 0, 0\n",
    "\n",
    "for prediction, correct_value in zip(ypreds, y_test):\n",
    "    if prediction == 1 and correct_value == 1:\n",
    "        tpos += 1\n",
    "    if prediction == 1 and correct_value == 0:\n",
    "        fpos += 1\n",
    "    if prediction == 0 and correct_value == 0:\n",
    "        tneg += 1\n",
    "    if prediction == 0 and correct_value == 1:\n",
    "        fneg += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "recall = (tpos) / (tpos + fneg)\n",
    "skrecall = sklearn.metrics.recall_score(y_test, ypreds)\n",
    "skpres = sklearn.metrics.precision_score(y_test, ypreds)\n",
    "skac = clf.score(x_test, y_test)\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'Sklearn recall: {sklearn.metrics.recall_score(y_test, ypreds):.2f}')\n",
    "precision = (tpos) / (tpos + fpos)\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Skearn precision: {sklearn.metrics.precision_score(y_test, ypreds):.2f}')\n",
    "accuracy = (tpos + tneg) / (tpos + tneg + fpos + fneg)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Sklearn accuracy: {clf.score(x_test, y_test):.2f}')\n",
    "print(f'Average score={((recall+skrecall+skpres+precision+skac+accuracy)/6)*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting All The Things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = open(\"mixed_test_reviews.txt\").readlines()\n",
    "\n",
    "newTests = []\n",
    "for rvw in tests:\n",
    "    rvw = rvw.replace(\"\\n\", \"\")\n",
    "    newTests.append(rvw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = (clf.predict(cv.transform(newTests)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = []\n",
    "for pred in preds:\n",
    "    pred = round(pred)\n",
    "    preds2.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res.txt', 'w') as f:\n",
    "    for prid in preds2:\n",
    "        f.write(\"%s\\n\" % prid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "jamesleo.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
